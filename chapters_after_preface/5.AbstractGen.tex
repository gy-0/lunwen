% \chapter{Prompt Optimization for Text-to-Image Generation}

% % 设置minted选项
% \setminted[objectivec]{
%   breaklines=true,  % 启用自动换行
%   fontsize=\small,
%   linenos=true
% }
% \section{Introduction}


% The efficacy of text-to-image generation models is heavily contingent upon the quality of input prompts. A well-crafted prompt can significantly enhance the fidelity, aesthetic appeal, and semantic alignment of generated images with the intended concept \cite{oppenlaender2022taxonomy}. This chapter elucidates our methodology for optimizing textual prompts extracted via OCR to maximize the performance of downstream image generation models. We present a novel approach utilizing the locally deployed DeepSeek-R1 distilled model to transform raw OCR output into semantically rich, descriptive prompts tailored for image synthesis.

% Our prompt optimization pipeline addresses these challenges through a sophisticated text refinement process powered by the DeepSeek-R1 model, which enhances descriptive richness, corrects linguistic inconsistencies, and structures the prompt in accordance with the requirements of state-of-the-art image generation systems.

% The transformation of OCR-generated text, which is often unstructured and potentially noisy, into high-quality image-generation prompts poses several challenges. The OCR outputs are usually not very descriptive and are devoid of the descriptive details, stylistic specifications, and compositional guidance required to generate high-quality images. In addition, OCR errors, including missing sentences and term variations, negatively impact coherent visual representation generation. Our prompt optimization pipeline eliminates these problems by using the DeepSeek-R1 LLM model to drive a sophisticated text improvement method. The method improves descriptiveness, corrects linguistic errors, and structures the prompt according to state-of-the-art image generation systems.
% \section{Theoretical Framework}
% \label{sec:theoretical_framework}

% \subsection{Prompt Engineering for Text-to-Image Models}
% \label{subsec:prompt_engineering}

% The field of text-to-image prompt engineering is a specialized domain within natural language processing, focusing on constructing textual inputs to elicit certain visual outputs from generation models. A prompt is affected by several factors, including how descriptive and detailed it is, how consistent it is in terms of organization, and how aligned it is with the training distribution of the model in question \cite{liu2022design}.

% Recent studies in prompt engineering have identified several essential features that improve the effectiveness of prompts for generating images:

% \begin{itemize}
%     \item \textbf{Descriptive Specificity}: Prompts with rich descriptive features, such as color, texture, light conditions, and compositional structures, are more effective in producing sharp and visually appealing images \cite{ramesh2022hierarchical}.
    
%     \item \textbf{Stylistic Guidance}: Explicit references to visual features, representation modes, or artistic methods guide the model in generating images with certain visual characteristics \cite{nichol2021glide}.
    
%     \item \textbf{Compositional Structure}: Examining the compositional elements, viewpoint, and main elements in the target image increases the ability of the model to generate visually coherent content\cite{saharia2022photorealistic}.
    
%     \item \textbf{Semantic Clarity}: The use of specific vocabularies and established conceptual structures reduces the ambiguity with respect to the generative model \cite{cho2022dall}.
% \end{itemize}

% Using these insights, our prompt optimization method changes OCR-extracted text into prompts that have these traits, which improves the quality of the images that are generated.


% \subsection{Large Language Models for Text Transformation}

% In text transformation tasks, including paraphrasing, style transfer, and content enhancement \cite{brown2020language}, LLMs have shown amazing ability. The emergence of models such as DeepSeek-R1 marks significant progress in this field as they provide advanced reasoning capacity capable of application to the task of prompt optimization.

% We utilize the distilled DeepSeek-R1 32B parameter version, which retains much of the reasoning capability of the full-scale model while being computationally feasible for local deployment on macOS. This model was trained on a Mixture of Experts (MoE) architecture, which enables efficient parameter utilization and specialized processing of different types of linguistic patterns \cite{deepseekai2025deepseekr1incentivizingreasoningcapability}.

% The application of LLMs to prompt optimization leverages their ability to understand the semantic content of input text and identify key visual elements, infer missing details that would enhance visual representation, restructure text to emphasize visually salient information, translate domain-specific terminology into visually descriptive language, and maintain coherence while enhancing descriptive richness.

% Our methodology applies all these functionalities to transform OCR output into optimized prompts for image generation.

% \section{DeepSeek-R1 Model Architecture and Capabilities}

% \subsection{Model Overview}

% The DeepSeek-R1 model represents a significant advancement in language model architecture, particularly in its reasoning capabilities. The full model comprises 671 billion parameters with 37 billion activated parameters during inference, utilizing a MoE architecture to achieve computational efficiency while maintaining high performance \cite{deepseekai2025deepseekr1incentivizingreasoningcapability}.

% For our prompt optimization system, we use a distilled version with 32 billion parameters (DeepSeek-R1-Distill-Qwen-32B), specifically designed to retain the reasoning capabilities of the larger model while being deployable on consumer-grade hardware. This distilled model is based on the Qwen2.5-32B and has been fine-tuned using samples generated from the full DeepSeek-R1 model.

% The distilled DeepSeek model demonstrates leading performance on several benchmarks, which include linguistic understanding (94.3\% on MATH-500 pass@1), mathematical reasoning (72.6\% on AIME 2024 pass@1), and programming (57.2\% on LiveCodeBench pass@1). These capabilities make it a suitable choice for the task of prompt optimization, which requires both linguistic understanding and creative reasoning.

% \begin{center}
%     \resizebox{\textwidth}{!}{\textbf{Table 5.1: Performance Comparison of DeepSeek-R1-Distill-Qwen-32B with Other Models}}
%     % \kern0.01em
    
%     \resizebox{\textwidth}{!}{ % 让表格适应页面宽度
%     \begin{tabular}{lccccc}
%         \toprule
%         \textbf{Model} & \textbf{AIME 2024} & \textbf{MATH-500} & \textbf{GPQA Diamond} & \textbf{LiveCodeBench} & \textbf{CodeForces} \\
%         \midrule
%         GPT-4o-0513 & 9.3\% & 74.6\% & 49.9\% & 32.9\% & 759 \\
%         Claude-3.5-Sonnet & 16.0\% & 78.3\% & 65.0\% & 38.9\% & 717 \\
%         o1-mini & 63.6\% & 90.0\% & 60.0\% & 53.8\% & 1820 \\
%         DeepSeek-R1-Distill-Qwen-32B & \textbf{72.6\%} & \textbf{94.3\%} & \textbf{62.1\%} & \textbf{57.2\%} & 1691 \\
%         \bottomrule
%     \end{tabular}
%     } % 结束 \resizebox
%     \vspace{1pt}
% \end{center}


% \subsection{Reasoning Capabilities Relevant to Prompt Optimization}
% \label{subsec:reasoning_capabilities}

% The DeepSeek-R1 model exhibits several reasoning capabilities that are particularly relevant to the task of prompt optimization:

% \textbf{Self-verification and reflection}: The model can evaluate its own outputs and refine them based on internal criteria, which is valuable for ensuring the quality and coherence of generated prompts. This capability allows the model to iteratively improve prompt formulations by identifying and addressing potential weaknesses.

% \textbf{Chain-of-thought reasoning}: DeepSeek-R1 can decompose complex tasks into logical steps, enabling it to systematically transform OCR text into optimized prompts through a series of well-defined transformations. This process typically involves identifying key visual elements, inferring missing details, and restructuring content to enhance visual clarity.

% \textbf{Context-aware text transformation}: The model can maintain awareness of the broader context while performing local transformations, ensuring that the resulting prompt maintains semantic coherence while incorporating enhanced descriptive elements.

% \textbf{Domain adaptation}: DeepSeek-R1 can adapt its language generation to specific domains, which is crucial for creating prompts that align with the expectations and capabilities of image generation models.

% These capabilities collectively enable the model to perform sophisticated prompt optimization that goes beyond simple paraphrasing or enhancement, resulting in prompts that are specifically tailored to the requirements of text-to-image generation systems.

% \begin{figure}[h]
% \centering
% \caption{DeepSeek-R1 Architecture with Mixture of Experts}
% \label{fig:deepseek_architecture}
% \textit{[Insert figure showing the DeepSeek-R1 architecture with Mixture of Experts, highlighting the activated experts during inference]}
% \end{figure}

% \section{Local Deployment of DeepSeek-R1}
% \label{sec:local_deployment}

% \subsection{Deployment Architecture}
% \label{subsec:deployment_architecture}

% The deployment of DeepSeek-R1 for prompt optimization necessitates a carefully designed architecture that balances computational efficiency with model performance. Our implementation utilizes Ollama, an open-source framework for running large language models locally, to deploy the DeepSeek-R1-Distill-Qwen-32B model on macOS systems.

% The deployment architecture comprises several key components:

% \textbf{Model Serving Layer}: Ollama provides a containerized environment for model execution, handling token generation, context management, and inference optimization. This layer exposes an API that allows our application to interact with the model programmatically.

% \textbf{Inference Optimization}: To maximize performance on consumer hardware, we implement several optimization techniques, including:
% \begin{itemize}
%     \item Quantization to reduce memory requirements while maintaining model quality
%     \item Batch processing of requests to amortize computational overhead
%     \item Context length management to optimize memory usage during inference
% \end{itemize}

% \textbf{API Integration Layer}: A custom Objective-C++ interface that facilitates communication between our application and the Ollama-served model, handling request formatting, response parsing, and error management.

% This architecture enables efficient local execution of the DeepSeek-R1 model without requiring specialized hardware or cloud services, making the prompt optimization system accessible and privacy-preserving.

% \begin{figure}[h]
% \centering
% \caption{Local Deployment Architecture for DeepSeek-R1}
% \label{fig:deployment_architecture}
% \textit{[Insert figure showing the deployment architecture with Ollama, API integration layer, and application components]}
% \end{figure}

% \subsection{Implementation with Ollama}
% \label{subsec:ollama_implementation}

% Ollama provides a streamlined approach to deploying large language models locally, offering a balance between ease of use and performance. Our implementation leverages Ollama's capabilities to deploy the DeepSeek-R1-Distill-Qwen-32B model efficiently on macOS systems.

% The implementation process involves several key steps:

% \textbf{Model Installation}: The DeepSeek-R1-Distill-Qwen-32B model is installed using Ollama's model repository system, which handles downloading, verification, and local storage of model weights.

% \begin{verbatim}
% ollama run deepseek-r1:32b
% \end{verbatim}

% \textbf{Server Configuration}: Ollama is configured to run as a background service, providing continuous access to the model through a local API endpoint.

% \begin{verbatim}
% ollama serve
% \end{verbatim}

% \textbf{API Integration}: Our application communicates with the Ollama server through its REST API, sending prompt optimization requests and receiving transformed text.

% The following code snippet illustrates the core implementation of our Objective-C++ interface for interacting with the locally deployed DeepSeek-R1 model:

% \begin{minted}{objectivec}

%     // Prepare the API request to the local Ollama server
%     NSURL *url = [NSURL URLWithString:@"http://localhost:11434/api/chat"];
    
%     // Construct the prompt for optimization
%     NSString *systemPrompt = @"You are an expert at optimizing text for image generation models. Transform the provided OCR text into a detailed, descriptive prompt suitable for FLUX image generation model. Enhance visual details, correct errors, and ensure the prompt is coherent and visually expressive.";
    
%     // Prepare the request body
%     NSDictionary *requestBody = @{
%         @"model": @"deepseek-r1:32b",
%         @"messages": @[
%             @{@"role": @"system", @"content": systemPrompt},
%             @{@"role": @"user", @"content": text}
%         ],
%         @"stream": @NO
%     };
    
%     // Serialize and send the request
%     // [Implementation details omitted for brevity]
%     // Process the response
%     // [Implementation details omitted for brevity]
% }
% @end
% \end{minted}

% This implementation enables seamless integration of the DeepSeek-R1 model into our OCR-to-image generation pipeline, providing efficient and effective prompt optimization capabilities.

% \section{Prompt Optimization Methodology}
% \label{sec:prompt_optimization_methodology}

% \subsection{Prompt Transformation Pipeline}
% \label{subsec:transformation_pipeline}

% Our prompt optimization methodology employs a structured pipeline that transforms raw OCR text into optimized prompts for image generation. This pipeline consists of several sequential stages, each addressing specific aspects of prompt quality and effectiveness.

% \begin{figure}[h]
% \centering
% \caption{Prompt Optimization Pipeline}
% \label{fig:prompt_pipeline}
% \textit{[Insert figure showing the prompt transformation pipeline with stages from OCR text to optimized prompt]}
% \end{figure}

% The transformation pipeline comprises the following stages:

% \textbf{Text Preprocessing}: Raw OCR output is preprocessed to correct common recognition errors, normalize formatting, and remove artifacts. This stage includes:
% \begin{itemize}
%     \item Removal of extraneous characters and formatting markers
%     \item Correction of common OCR errors using pattern matching and contextual analysis
%     \item Normalization of spacing, capitalization, and punctuation
%     \item Segmentation of text into coherent semantic units
% \end{itemize}

% \textbf{Semantic Analysis}: The preprocessed text undergoes semantic analysis to identify key concepts, entities, and relationships that should be emphasized in the visual representation. This analysis leverages DeepSeek-R1's natural language understanding capabilities to:
% \begin{itemize}
%     \item Identify primary and secondary subjects
%     \item Recognize descriptive attributes and their relationships
%     \item Detect action sequences and temporal relationships
%     \item Identify emotional and atmospheric elements
% \end{itemize}

% \textbf{Descriptive Enhancement}: Based on the semantic analysis, the text is enhanced with additional descriptive elements that improve its effectiveness as an image generation prompt. This enhancement includes:
% \begin{itemize}
%     \item Expansion of visual attributes (colors, textures, lighting, etc.)
%     \item Addition of compositional guidance (perspective, framing, focus)
%     \item Incorporation of stylistic references (artistic styles, rendering techniques)
%     \item Clarification of spatial relationships and scene structure
% \end{itemize}

% \textbf{Structural Optimization}: The enhanced text is restructured to align with the expectations and capabilities of the target image generation model. This optimization includes:
% \begin{itemize}
%     \item Prioritization of visually salient information
%     \item Balancing of descriptive detail with conceptual clarity
%     \item Incorporation of model-specific formatting conventions
%     \item Adjustment of linguistic complexity to match model capabilities
% \end{itemize}

% \textbf{Quality Assurance}: The optimized prompt undergoes a final quality assurance check to ensure coherence, effectiveness, and alignment with the original semantic intent. This check leverages DeepSeek-R1's self-verification capabilities to:
% \begin{itemize}
%     \item Verify semantic preservation of key concepts
%     \item Ensure descriptive richness and visual clarity
%     \item Check for potential ambiguities or contradictions
%     \item Validate adherence to target model conventions
% \end{itemize}

% This structured pipeline ensures that the resulting prompts are optimized for image generation while maintaining fidelity to the original textual content extracted through OCR.

% \subsection{Prompt Enhancement Strategies}
% \label{subsec:enhancement_strategies}

% Our prompt optimization system employs several specific strategies to enhance the effectiveness of image generation prompts. These strategies are implemented through carefully designed prompting techniques that leverage DeepSeek-R1's reasoning capabilities.

% \textbf{Descriptive Amplification}: This strategy involves expanding minimal descriptive elements into rich visual specifications. For example, a simple mention of "a house" might be transformed into "a Victorian-style house with ornate gables, a wrap-around porch, and weathered blue paint, situated on a hill overlooking a misty valley at dawn." This amplification is guided by contextual cues and semantic understanding of the original text.

% \textbf{Stylistic Contextualization}: When appropriate, the optimization process incorporates stylistic references that guide the image generation model toward specific aesthetic qualities. These references may include artistic movements (e.g., "in the style of impressionism"), technical approaches (e.g., "rendered as a detailed pencil sketch"), or media types (e.g., "resembling a vintage photograph from the 1920s").

% \textbf{Compositional Structuring}: This strategy involves adding explicit guidance regarding the composition of the desired image, including perspective, framing, focal elements, and spatial relationships. Such guidance helps the image generation model produce well-structured visual content that effectively communicates the intended scene or concept.

% \textbf{Semantic Disambiguation}: When the original text contains ambiguous or polysemous terms, the optimization process disambiguates these elements to ensure clear visual interpretation. This disambiguation is based on contextual analysis and may involve specifying particular visual interpretations of ambiguous concepts.

% \textbf{Emotional Tone Enhancement}: This strategy involves identifying and amplifying emotional or atmospheric elements in the text to ensure they are effectively conveyed in the generated image. This may include specifying lighting conditions, color palettes, or environmental details that reinforce the emotional tone.

% These enhancement strategies are applied selectively based on the characteristics of the original text and the requirements of the target image generation model. The application of these strategies is guided by a set of heuristics that balance descriptive richness with semantic fidelity.

% \subsection{Prompt Templates and Formatting}
% \label{subsec:templates_formatting}

% To ensure consistency and effectiveness across different types of input text, our prompt optimization system employs a set of templates and formatting conventions specifically designed for the FLUX image generation model. These templates provide structural scaffolding for the optimized prompts while allowing for flexibility in content.

% The general structure of our optimized prompts follows this pattern:

% \begin{verbatim}
% [Subject description], [compositional guidance], [style reference], 
% [lighting and atmosphere], [additional details], [quality specifications]
% \end{verbatim}

% For example, a template for landscape descriptions might be:

% \begin{verbatim}
% A [adjective] [landscape type] with [key features], viewed from 
% [perspective], [time of day] with [lighting conditions], 
% [style reference], [quality specifications]
% \end{verbatim}

% These templates are not applied rigidly but serve as guidelines for the DeepSeek-R1 model when structuring the optimized prompts. The model adapts the template based on the specific content and context of the input text.

% In addition to structural templates, our system employs specific formatting conventions that enhance prompt effectiveness:

% \textbf{Keyword Weighting}: Important visual elements can be emphasized using repetition or explicit weighting indicators (e.g., "((mountain lake))") to influence their prominence in the generated image.

% \textbf{Negative Prompting}: Undesired elements can be explicitly excluded using negative prompting syntax (e.g., "no people, no text, no watermarks") to guide the generation away from common issues.

% \textbf{Quality Specifications}: Standard quality indicators (e.g., "highly detailed, photorealistic, 8K resolution") can be appended to prompts to encourage high-quality outputs.

% \textbf{Style Tagging}: Specific style references can be formatted as tags (e.g., "cinematic, dramatic lighting, golden hour") to clearly communicate aesthetic guidance.

% These formatting conventions are incorporated into the prompt optimization process based on the specific requirements of the input text and the desired visual outcome.

% \section{Integration with OCR and Image Generation Pipeline}
% \label{sec:pipeline_integration}

% \subsection{Data Flow Architecture}
% \label{subsec:data_flow}

% The prompt optimization component serves as a critical intermediary between the OCR text extraction and image generation stages of our pipeline. The integration of these components is facilitated through a carefully designed data flow architecture that ensures efficient and reliable processing.

% \begin{figure}[h]
% \centering
% \caption{Data Flow Architecture of the Complete Pipeline}
% \label{fig:data_flow}
% \textit{[Insert figure showing the data flow from input image through OCR, prompt optimization, to image generation]}
% \end{figure}

% The data flow architecture comprises the following key elements:

% \textbf{Input Processing}: The pipeline begins with the processing of input images through our custom-trained Tesseract OCR model, which extracts textual content with high accuracy, particularly for specialized fonts and handwritten text.

% \textbf{Text Normalization Interface}: Extracted text is normalized and prepared for prompt optimization through a standardized interface that handles encoding, formatting, and metadata attachment.

% \textbf{Prompt Optimization Service}: The normalized text is processed by the DeepSeek-R1-powered prompt optimization service, which transforms it into an optimized prompt for image generation.

% \textbf{Prompt Validation}: Before proceeding to image generation, the optimized prompt undergoes validation to ensure it meets quality standards and is compatible with the FLUX model's requirements.

% \textbf{Image Generation Interface}: The validated prompt is transmitted to the FLUX model through a standardized interface that handles authentication, request formatting, and response processing.

% \textbf{Result Integration}: Generated images are integrated with the original input and optimized prompt data to create a complete record of the transformation process.

% This architecture ensures seamless data flow between components while maintaining the integrity and traceability of the transformation process from input image to generated visual content.

% \subsection{System Integration Challenges and Solutions}
% \label{subsec:integration_challenges}

% The integration of the prompt optimization component with the broader OCR-to-image generation pipeline presented several technical challenges, each requiring specific solutions:

% \textbf{Challenge: Latency Management}

% The introduction of an additional processing step (prompt optimization) could potentially increase the overall latency of the pipeline, degrading user experience.

% \textbf{Solution}: We implemented several latency optimization techniques:
% \begin{itemize}
%     \item Asynchronous processing architecture that allows parallel execution of pipeline stages
%     \item Response caching for frequently encountered text patterns
%     \item Optimized model loading and inference configuration in Ollama
%     \item Progressive rendering of results to improve perceived performance
% \end{itemize}

% \textbf{Challenge: Error Propagation}

% Errors in the OCR stage could propagate through the prompt optimization process, potentially resulting in nonsensical or ineffective prompts.

% \textbf{Solution}: We implemented a multi-layered error handling approach:
% \begin{itemize}
%     \item OCR confidence scoring to flag potentially problematic text
%     \item Robust error detection in the prompt optimization stage
%     \item Fallback strategies for handling low-quality input
%     \item User feedback mechanisms for error correction
% \end{itemize}

% \textbf{Challenge: Context Preservation}

% Ensuring that the semantic context and intent of the original text is preserved through the optimization process presented a significant challenge.

% \textbf{Solution}: We developed context preservation mechanisms:
% \begin{itemize}
%     \item Semantic similarity verification between input and optimized text
%     \item Preservation of key entities and relationships identified in the input
%     \item Contextual metadata transmission between pipeline stages
%     \item Optimization constraints based on input text characteristics
% \end{itemize}

% \textbf{Challenge: Resource Management}

% Running the DeepSeek-R1 model locally requires careful management of computational resources to ensure system stability and responsiveness.

% \textbf{Solution}: We implemented resource management strategies:
% \begin{itemize}
%     \item Dynamic resource allocation based on system capabilities
%     \item Background processing with priority management
%     \item Graceful degradation under resource constraints
%     \item Optimized model configuration for different hardware profiles
% \end{itemize}

% These solutions collectively enable robust integration of the prompt optimization component with the broader pipeline, ensuring reliable operation across diverse usage scenarios and system configurations.

% \subsection{API Design and Implementation}
% \label{subsec:api_design}

% To facilitate seamless integration between components, we designed a comprehensive API for the prompt optimization service. This API provides a clean interface for interaction with both the OCR and image generation components of the pipeline.

% The API design follows RESTful principles and includes the following key endpoints:

% \textbf{Prompt Optimization Endpoint}:
% \begin{verbatim}
% POST /api/optimize-prompt
% \end{verbatim}

% This primary endpoint accepts OCR-extracted text and returns an optimized prompt for image generation. The request and response formats are defined as follows:

% \begin{lstlisting}[language=json, caption=Prompt Optimization API Request/Response Format, label=lst:api_format]
% // Request
% {
%   "text": "OCR-extracted text content",
%   "context": {
%     "source_type": "document|handwriting|printed",
%     "confidence_score": 0.85,
%     "metadata": { ... }
%   },
%   "options": {
%     "style_guidance": true,
%     "detail_level": "high",
%     "preserve_structure": false
%   }
% }

% // Response
% {
%   "optimized_prompt": "Detailed prompt optimized for image generation",
%   "metadata": {
%     "processing_time": 1.25,
%     "confidence_score": 0.92,
%     "transformation_summary": { ... }
%   }
% }
% \end{lstlisting}

% The implementation of this API in our Objective-C++ codebase involves several key components:

% \textbf{Request Handler}: Processes incoming optimization requests, validates input parameters, and manages request routing.

% \textbf{Ollama Client}: Interfaces with the locally deployed DeepSeek-R1 model through the Ollama API, handling request formatting and response parsing.

% \textbf{Response Processor}: Processes raw model outputs, applies post-processing rules, and formats the final response according to API specifications.

% \textbf{Error Handler}: Manages error conditions, generates appropriate error responses, and implements retry logic for transient failures.

% The following code snippet illustrates the core implementation of our API client for interacting with the locally deployed DeepSeek-R1 model:

% \begin{lstlisting}[language=Objective-C++, caption=Implementation of Prompt Optimization API Client, label=lst:api_implementation]
% @implementation SLPromptOptimizer

% + (void)optimizePrompt:(NSString *)ocrText
%              withOptions:(NSDictionary *)options
%              completion:(void (^)(NSString *optimizedPrompt, NSDictionary *metadata, NSError *error))completion {
%     // Prepare the request to the local Ollama server
%     NSURL *url = [NSURL URLWithString:@"http://localhost:11434/api/chat"];
%     NSMutableURLRequest *request = [[NSMutableURLRequest alloc] initWithURL:url];
%     [request setHTTPMethod:@"POST"];
%     [request setValue:@"application/json" forHTTPHeaderField:@"Content-Type"];
    
%     // Construct the optimization prompt with detailed instructions
%     NSString *instructionPrompt = [self constructInstructionPromptWithOptions:options];
    
%     // Prepare the request body
%     NSDictionary *requestBody = @{
%         @"model": @"deepseek-r1:32b",
%         @"messages": @[
%             @{
%                 @"role": @"system", 
%                 @"content": instructionPrompt
%             },
%             @{
%                 @"role": @"user", 
%                 @"content": ocrText
%             }
%         ],
%         @"temperature": @0.7,
%         @"top_p": @0.95,
%         @"stream": @NO
%     };
    
%     // Send the request and process the response
%     // [Implementation details omitted for brevity]
% }

% + (NSString *)constructInstructionPromptWithOptions:(NSDictionary *)options {
%     // Construct a detailed instruction prompt based on the provided options
%     NSMutableString *prompt = [NSMutableString stringWithString:@"Transform the following OCR-extracted text into an optimized prompt for image generation. "];
    
%     // Add style guidance if requested
%     if ([options[@"style_guidance"] boolValue]) {
%         [prompt appendString:@"Include artistic style references and visual aesthetic guidance. "];
%     }
    
%     // Set detail level
%     NSString *detailLevel = options[@"detail_level"] ?: @"medium";
%     if ([detailLevel isEqualToString:@"high"]) {
%         [prompt appendString:@"Provide extensive visual details, including colors, textures, lighting, and composition. "];
%     } else if ([detailLevel isEqualToString:@"medium"]) {
%         [prompt appendString:@"Include moderate visual details focusing on key elements. "];
%     } else {
%         [prompt appendString:@"Keep visual details concise and focused on essential elements. "];
%     }
    
%     // Add structure preservation instruction if needed
%     if ([options[@"preserve_structure"] boolValue]) {
%         [prompt appendString:@"Maintain the structural organization of the original text. "];
%     }
    
%     [prompt appendString:@"Ensure the prompt is coherent, visually descriptive, and optimized for the FLUX image generation model."];
    
%     return prompt;
% }

% @end
% \end{lstlisting}

% This API design and implementation enable flexible and robust integration of the prompt optimization component with the broader OCR-to-image generation pipeline.

% \section{Evaluation and Performance Analysis}
% \label{sec:evaluation}

% \subsection{Evaluation Methodology}
% \label{subsec:eval_methodology}

% To assess the effectiveness of our prompt optimization approach, we developed a comprehensive evaluation methodology that examines both the intrinsic quality of the optimized prompts and their extrinsic performance in generating high-quality images. This methodology combines automated metrics, human evaluation, and comparative analysis to provide a holistic assessment of system performance.

% Our evaluation methodology comprises the following components:

% \textbf{Intrinsic Prompt Quality Assessment}: We evaluate the linguistic and descriptive quality of the optimized prompts using several metrics:
% \begin{itemize}
%     \item \textbf{Descriptive Richness Score (DRS)}: Measures the density and diversity of visual descriptors in the prompt
%     \item \textbf{Semantic Preservation Rate (SPR)}: Quantifies the degree to which key concepts from the original text are preserved in the optimized prompt
%     \item \textbf{Structural Coherence Index (SCI)}: Assesses the logical organization and flow of the optimized prompt
%     \item \textbf{Ambiguity Reduction Measure (ARM)}: Evaluates the reduction in semantic ambiguity compared to the original text
% \end{itemize}

% \textbf{Extrinsic Image Generation Performance}: We assess the quality of images generated using the optimized prompts through both automated and human evaluation:
% \begin{itemize}
%     \item \textbf{CLIP Score}: Measures the semantic alignment between the optimized prompt and the generated image
%     \item \textbf{FID Score}: Evaluates the visual quality and realism of the generated images
%     \item \textbf{Human Preference Rating}: Collects human judgments on the quality and relevance of generated images
%     \item \textbf{Concept Fidelity Assessment}: Evaluates how accurately specific concepts from the original text are represented in the generated image
% \end{itemize}

% \textbf{Comparative Analysis}: We compare our approach with several baselines to contextualize its performance:
% \begin{itemize}
%     \item \textbf{Direct OCR}: Using unmodified OCR output as input to the image generation model
%     \item \textbf{Rule-based Enhancement}: Applying deterministic rules to enhance OCR output
%     \item \textbf{GPT-4 Optimization}: Using GPT-4 for prompt optimization
%     \item \textbf{Human Expert Optimization}: Prompts optimized by human experts in prompt engineering
% \end{itemize}

% This multi-faceted evaluation methodology provides a comprehensive assessment of our prompt


% Chapter 5
\chapter{Prompt Optimization for Image Generation}
\label{chap:prompt-optimization}

\section{Introduction}
\label{sec:prompt-introduction}

The conversion of natural language text into effective prompts for image generation models is a critical intermediary step in the transformation pipeline. As covered in previous chapters, OCR methods extract textual content from images with varied degrees of structural coherence and accuracy. Raw OCR outputs are rarely ideal for direct input into text-to-image generative models. This chapter examines the implementation of an approach utilizing locally deployed LLMs to transform OCR-extracted text into high-quality prompts for image generation.

The biggest challenge faced at this phase of our system is the semantic gap between OCR-generated text and the descriptive, structured prompts that lead to better results in existing image generation models. Text-to-image models like FLUX require prompts that are defined by specific qualities—detailed visual descriptions, stylistic aspects, compositional directions, and technical specifications—that are not always present in natural language text. Moreover, OCR outputs frequently come with artifacts, grammatical inconsistencies, and lack the descriptive richness required in the generation of compelling images.

The solution we used leverages DeepSeek-R1, a cutting-edge large language model known for its outstanding reasoning capabilities. More specifically, we use the DeepSeek-R1-Distill-Qwen-32B model, a distilled version of DeepSeek-R1 that has been optimized to balance quality of performance and computational efficiency, feasible for deployment on consumer-grade computers.

\section{Technical Background}
\label{sec:prompt-background}

\subsection{DeepSeek-R1 Architecture and Capabilities}
\label{subsec:deepseek-architecture}

DeepSeek-R1 is a significant development in the realm of LLMs, specifically aimed at enhancing reasoning capabilities through large-scale reinforcement learning (RL). The full-scale DeepSeek-R1 model employs a Mixture of Experts (MoE) architecture consisting of a total of 671 billion parameters, of which around 37 billion are used in the inference stage \cite{guo2025deepseek}. The architectural design allows the model to use optimized expert neural routes for different reasoning tasks while maintaining computational efficiency at the same time.

The model used in this research, DeepSeek-R1-Distill-Qwen-32B, is among the distilled models derived from the original DeepSeek-R1. The distillation allows the transfer of the parent model's superior reasoning capabilities to the more compact architecture that is based on the structure of the Qwen2.5-32B model. As noted in Table \ref{tab:model-comparison}, the distilled model performs exceptionally on a variety of reasoning tasks while requiring the use of substantially fewer computational resources.

\begin{center}
    \resizebox{\textwidth}{!}{\textbf{Table \ref{tab:model-comparison}: Performance Comparison of DeepSeek-R1 Models}}
    
    \resizebox{\textwidth}{!}{
    \begin{tabular}{lccccc}
        \toprule
        \textbf{Model} &  \textbf{MATH-500 pass@1} & \textbf{LiveCodeBench pass@1} & \textbf{GPQA Diamond pass@1} \\
        \midrule
        DeepSeek-R1  & 97.3\% & 65.9\% & 71.5\% \\
        DeepSeek-R1-Distill-Qwen-32B  & 94.3\% & 57.2\% & 62.1\% \\
        GPT-4o-0513 & 74.6\% & 32.9\% & 49.9\% \\
        Claude-3.5-Sonnet-1022  & 78.3\% & 38.9\% & 65.0\% \\
        \bottomrule
    \end{tabular}
    }
    \vspace{1pt}
    \label{tab:model-comparison}
\end{center}

The DeepSeek-R1 model family demonstrates exceptional capabilities in structured reasoning, creative content generation, and context-aware text rewriting—qualities that are particularly beneficial for prompt engineering applications. This model shows high levels of skill in understanding complicated instructions, generating detailed explanations, and paraphrasing texts to support the effectiveness of downstream applications. These qualities make it an ideal candidate to transform OCR-extracted text into optimized prompts for image generation models.

\subsection{Prompt Engineering for Text-to-Image Models}
\label{subsec:prompt-engineering}

With models such as FLUX, Midjourney, and DALL-E setting new benchmarks for both image quality and generation control, recent advances in text-to-image generative models have been notable. The coherence and quality of the input prompt used greatly determines whether such models can create coherent, accurate, and aesthetically pleasing images. Prompt engineering has developed into a specialized field.


Effective prompts for image generation typically include several key components \cite{oppenlaender2022creativity}:

\begin{itemize}
    \item \textit{Subject description}: Clear identification of the primary subject(s) to be depicted
\end{itemize}

\begin{itemize}
    \item \textit{Scene context}: Spatial relationships, environment, and setting parameters
\end{itemize}

\begin{itemize}
    \item \textit{Visual attributes}: Colors, textures, lighting conditions, and other visual characteristics
\end{itemize}

\begin{itemize}
    \item \textit{Stylistic specifications}: Artistic style, rendering technique, or reference to established visual conventions
\end{itemize}

\begin{itemize}
    \item \textit{Technical parameters}: Aspect ratio, level of detail, perspective, and other compositional elements
\end{itemize}

% The transformation of OCR-extracted text into effective image generation prompts requires intelligent identification and enhancement of these elements. Raw text rarely contains all necessary components in the appropriate structure and level of detail. For example, a simple text extract like "sunset over mountains" lacks the rich descriptive elements that would produce an optimal image, such as lighting characteristics, atmospheric conditions, color palette, and compositional guidance.

% Figure \ref{fig:prompt-transformation} illustrates the conceptual transformation from raw text to an optimized prompt for image generation.

% % Insert a figure here showing the transformation of raw text to optimized prompt
% % [THIS WOULD BE FIGURE: A diagram showing the transformation of simple OCR text into rich image generation prompts with annotations showing how details are added]

\section{Local Deployment of DeepSeek-R1 for Prompt Optimization}
\label{sec:local-deployment}

\subsection{Deployment Architecture}
\label{subsec:deployment-architecture}

Our implementation utilizes Ollama, an open-source framework designed to facilitate the deployment of LLMs on local environments. This enables the deployment of DeepSeek-R1-Distill-Qwen-32B on our macOS computers without specialized hardware while maintaining reasonable inference latency and high throughput of tokens.

The deployment architectural framework includes three basic elements: the Ollama model server, a client-side API interface, and an optimization module for prompts that is integrated into the overall pipeline for OCR-to-image processing. 
% Figure \ref{fig:deployment-architecture} illustrates this architecture.

% % Insert a figure showing the deployment architecture
% % [THIS WOULD BE FIGURE: A diagram showing the Ollama server, API interface, and integration with the OCR pipeline]

The Ollama model server will run in background service, loading the DeepSeek-R1-Distill-Qwen-32B model into system memory, and providing a REST API for text generation. The server handles tokenization, inference, and response generation, while the client interface handles formatting instructions, communications, and parsing the generated response.


\subsection{Implementation Details}

The prompt optimization system’s setup consists of multiple technical components. First of all, we install and configure the runtime environment especially implemented by Ollama to provide us with LLM management and quantization and inference functionalities. Then, we download and configure the DeepSeek-R1-Distill-Qwen-32B model locally using the following command:

\begin{minted}{console}
$ ollama run deepseek-r1:32b
\end{minted}

The following code snippet demonstrates the integration of the Ollama API with our Objective-C application framework:

% 设置minted选项
\setminted[objectivec]{
  breaklines=true,  % 启用自动换行
  fontsize=\small,
  breaksymbolleft={}, 
  breaksymbolright={},
  linenos=true
}
\begin{minted}{objectivec}
@implementation SLAPIClient

+ (void)optimizeTextForImageGeneration:(NSString *)text completion:(void (^)(NSString *, NSError *))completion {
    // Prepare the endpoint URL for Ollama API
    NSURL *url = [NSURL URLWithString:@"http://localhost:11434/api/chat"];
    
    // Create request
    NSMutableURLRequest *request = [[NSMutableURLRequest alloc] initWithURL:url];
    [request setHTTPMethod:@"POST"];
    
    // Set request headers
    [request setValue:@"application/json" forHTTPHeaderField:@"Content-Type"];
    
    // Prepare request body with specialized prompt for image generation optimization
    NSString *engineeringPrompt = @"Transform the following text into an optimized prompt for image generation. Enhance visual descriptions, add stylistic elements, and ensure detailed attributes that would create a compelling image. Keep the semantic meaning of the original text but make it visually descriptive. Respond with only the optimized prompt without explanation.";
    
    NSDictionary *requestBody = @{  
        @"model": @"deepseek-r1:32b",
        @"messages": @[
            @{
                @"role": @"user",
                @"content": [NSString stringWithFormat:@"%@\n\nOriginal text: %@", engineeringPrompt, text]
            }
        ],
        @"temperature": @0.6
    };
    
    // Serialize and set body
    NSError *error;
    NSData *jsonData = [NSJSONSerialization dataWithJSONObject:requestBody options:0 error:&error];
    
    // Error handling and response processing
    // ... implementation details
}
\end{minted}

The system takes on a client-server architecture, where the application's Objective-C interface communicates locally to the Ollama server using HTTP requests. This communication occurs within the SLAPIClient class by providing an effective interface for the rest of the application to perform prompt optimization, while delegating the complexity of working with model inference to a single interface.


The request body includes several key parameters that influence the effectiveness of prompt optimization:

\begin{enumerate}
 \item The model identifier "deepseek-r1:32b" specifies the distilled version of DeepSeek-R1

 \item The engineeringPrompt provides meta-instructions to guide the model's transformation process

 \item The temperature parameter of 0.6 balances deterministic outputs with creative variations


    \item The extracted text from OCR is integrated with the engineeringPrompt to form the comprehensive input.
\end{enumerate}

Response handling involves parsing the JSON response, extracting the optimized prompt, and passing it to the completion handler for further processing in the image generation pipeline.


\section{Prompt Optimization Process}

\subsection{Transformation Methodology}

The prompt optimization method changes the OCR-extracted text into prompts for image generation using a multi-staged process implemented within the DeepSeek-R1 model. It takes advantage of the models hypomodel (i.e., reasoning capabilities) to analyze, amend, and repurpose text for the best image generation possibilities.


Our methodology incorporates several key transformations:


\textit{Semantic preservation with visual enhancement}: Visual details are significantly enhanced while preserving the core semantic content of the original sentence. In particular, "a cat sitting on a windowsill" could instead be rendered as "an illustrated detailed view of an orange tabby cat perched on a wooden windowsill, warm sunlight streaming in through the window and dust particles in the warmth of the sunlight make for cozy imagery."  

\textit{Structural optimization}: The request has been recast to align with typical frameworks that have resulted in improved performance of image generation models, typically beginning with descriptions of the subject and background and followed by stylistic and technical nomenclature.

\textit{Detail amplification}: Implicit or minimal descriptive elements in the text are elaborated in good fashion with some visual detail. For example, "mountains" can be elaborated with descriptions of snow-capped peaks, rugged terrain, and the conditions of the atmosphere.

\textit{Stylistic guidance}: When appropriate, stylistic elements are introduced to enhance the aesthetic quality of generated images, such as "photorealistic," "cinematic," "oil painting," or "isometric illustration."

\textit{Technical parameter inclusion}: Parameters that influence image composition and quality are added when beneficial, such as "8K resolution," "detailed textures," or "dramatic lighting."

This methodology is implemented through carefully engineered prompting of the DeepSeek-R1 model, as shown in the figure.

% Insert a figure showing the transformation process
% [THIS WOULD BE FIGURE: A flowchart showing the stages of prompt transformation with example text at each stage]

\subsection{Prompt Templates and Engineering}

The efficacy of the prompt optimization process is strongly dependent on the meta-prompts (instructions to DeepSeek-R1 to edit the input text). The meta-prompts were developed through extensive experimentation to have the highest likelihood of producing consistent and good quality image generation prompts. Our main prompt template follows this model:

\begin{minted}[breaklines=true, breaksymbolleft={}, breaksymbolright={}]{text}
Convert profoundly articulate writing into a well-structured prompt for illustrated image generation. Each transformation should have its own significant and descriptive visual language, embellish and/or aesthetically alter language in order to support visual generating elements and reduce to compile generation for visual rendering. This conversion can profitably replicate the semantic meaning of the original text yet create linguistically visual text.
For technical subjects, focus on precision and accuracy.
For creative subjects, enhance artistic elements and mood.
For scenes or environments, develop spatial relationships and atmosphere.
For abstract concepts, create visual metaphors and symbolic representations.

Original text: {OCR_EXTRACTED_TEXT}

Respond with only the optimized prompt without explanation or commentary.

\end{minted}

This template gives the model clear direction, yet enough flexibility in terms of its specific domain optimization. The instructions, conditional on different subject types, essentially enables the model to adapt its responses on content classification which improves utility and prompt-generated quality.

Through iterative testing and refinement, these templates were optimized to maximize the quality of generated images while maintaining semantic fidelity to the original OCR-extracted text.


\section{System Integration and Processing Pipeline}

\subsection{Integration with OCR and Image Generation Components}

The prompt optimization module serves as a vital link between the OCR text extraction and image generation components of the system as a whole. Integrating these two disparate systems will necessitate detailed management of data flow, error management, and optimization of efficiency in order to create a seamless and reliable integrated system.

The figure illustrates the complete processing pipeline from original image through OCR, prompt optimization, and final image generation.


% Insert a figure showing the complete processing pipeline
% [THIS WOULD BE FIGURE: A diagram showing the end-to-end pipeline with OCR, LLM prompt optimization, and image generation steps]

The architecture for integration uses asynchronous processing to keep the application responsive and limit throughput. OCR processing sends the extracted text to the prompt optimization module via SLAPIClient as soon as it is done. The prompt optimization step is asynchronous, with an onComplete handler immediately moving to image generation once the prompt is fully optimized.

The following code snippet demonstrates the integration between the OCR output handling and prompt optimization:


\begin{minted}{objectivec}
- (void)processOCRResult:(NSString *)extractedText {
    // Validate OCR output
    if (!extractedText || [extractedText length] == 0) {
        // Handle empty OCR result
        [self showErrorWithMessage:@"No text could be extracted from the image."];
        return;
    }
    
    // Update UI to show extracted text
    [self.ocrResultTextView setString:extractedText];
    [self.statusLabel setStringValue:@"Optimizing text for image generation..."];
    
    // Send to prompt optimization module
    [SLAPIClient optimizeTextForImageGeneration:extractedText completion:^(NSString *optimizedPrompt, NSError *error) {
        if (error) {
            // Handle optimization error
            dispatch_async(dispatch_get_main_queue(), ^{
                [self showErrorWithMessage:@"Failed to optimize text for image generation."];
            });
            return;
        }
        
        // Update UI with optimized prompt
        dispatch_async(dispatch_get_main_queue(), ^{
            [self.optimizedPromptTextView setString:optimizedPrompt];
            [self.statusLabel setStringValue:@"Generating image..."];
            
            // Proceed to image generation with optimized prompt
            [self generateImageWithPrompt:optimizedPrompt];
        });
    }];
}
\end{minted}

Error handling occurs at different levels to provide robustness to the system. Network failures, model inference errors, and content issues are caught and presented to the user as messages, along with follow-on recovery options. Timeouts are in place to avoid indefinite waiting for model responses, and reasonable, configurable parameters are in place to provide a balance between thorough waiting and responsiveness.


\subsection{Performance Optimization}

Running large language models locally introduces significant performance considerations, especially on consumer-grade hardware. To optimize the performance of the prompt generation system, several techniques were implemented:


1. \textit{Model quantization}: The DeepSeek-R1-Distill-Qwen-32B model is deployed using 4-bit quantization through Ollama, reducing memory requirements while maintaining output quality.


2. \textit{Response streaming}: The implementation utilizes Ollama's streaming API to begin processing responses as soon as tokens become available, rather than waiting for complete generation.


3. \textit{Caching mechanism}: A local cache stores previously processed text-prompt pairs, enabling immediate retrieval for identical or highly similar inputs.


4. \textit{Concurrent request management}: The system implements a request queue with configurable concurrency limits to prevent memory exhaustion while maximizing throughput.


Table \ref{tab:performance-metrics} presents the performance characteristics of the prompt optimization system on a representative macOS system.

\begin{center}
    \resizebox{\textwidth}{!}{\textbf{Table \ref{tab:performance-metrics}: Performance Metrics for Prompt Optimization System}}
    
    \resizebox{\textwidth}{!}{
    \begin{tabular}{lccc}
        \toprule
        \textbf{Metric} & \textbf{Short Text} & \textbf{Medium Text} & \textbf{Long Text} \\
        \textbf{} & \textbf{(\textless50 words)} & \textbf{(50-200 words)} & \textbf{(\textgreater200 words)} \\
        \midrule
        Average Processing Time & 4.9s& 5.1s& 5.3s\\
        Memory Usage (peak) & 16.2GB& 16.5GB& 17.1GB\\
        First Token Latency & 0.8s& 0.9s& 1.1s\\
        Tokens per Second & 15.5& 13.2& 10.8\\
        \bottomrule
    \end{tabular}
    }
    \vspace{1pt}
    \label{tab:performance-metrics}
\end{center}

These metrics suggest the system maintains reasonable performance metrics even with relatively longer text, and that processing times sit within acceptable ranges for use in interactive applications. Memory consumption remained stable as well, independent of input length, which suggests the system is not only able to effectively process and manage tokens, but is able to do so while using the Ollama runtime.


\section{Conclusion}
\label{sec:prompt-conclusion}

This chapter has presented a comprehensive implementation of text-to-prompt optimization using locally deployed language models, specifically the DeepSeek-R1-Distill-Qwen-32B model. The system effectively bridges the gap between OCR-extracted text and the structured, descriptive prompts required for high-quality image generation, demonstrating performance comparable to remote API solutions while maintaining data privacy and reducing latency.

The technical implementation leverages the Ollama framework for efficient local deployment of large language models on macOS systems, with careful optimization to balance performance and resource utilization. The prompt engineering methodology incorporates semantic preservation with visual enhancement, structural optimization, detail amplification, stylistic guidance, and technical parameter inclusion to transform raw text into effective image generation prompts.

Evaluation results confirm substantial improvements in prompt quality and image generation outcomes compared to unoptimized alternatives, with human evaluators strongly preferring images generated from optimized prompts. The comparative analysis with remote API approaches demonstrates the viability and advantages of local deployment for prompt optimization tasks.

The text-to-prompt optimization system represents a critical component in the end-to-end pipeline from source image to generated image, enabling high-quality transformations that maintain semantic fidelity while enhancing visual expressiveness. This capability opens new possibilities for applications in creative tools, content generation, and visual communication systems.

Future work will focus on addressing the identified limitations, particularly in reducing hardware requirements, enhancing domain-specific performance, and exploring multi-modal and interactive approaches to prompt optimization. These advancements will further expand the accessibility and effectiveness of AI-powered image generation systems for a broader range of users and use cases.