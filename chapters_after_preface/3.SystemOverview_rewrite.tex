\chapter{System Overview and Architecture}

This chapter presents the end-to-end system that transforms text contained in images into high-quality visual outputs by integrating custom-trained Tesseract OCR, image preprocessing, locally deployed large language model, and state-of-the-art text-to-image generation. The architecture is driven by practical constraints of privacy, latency, and robustness on commodity macOS hardware, while ensuring modularity for experimentation and rigorous evaluation. The design choices are grounded in prior advances in OCR and sequence model \cite{smith2007overview, graves2006connectionist, hochreiter1997long}, multimodal and LLM research \cite{qin2024comprehensive, jin2024mm}, as well as recent progress in open-source LLM deployment \cite{openai2025gptoss} and diffusion-based image synthesis \cite{blackforestlabs2024flux, rombach2025flux}.

\section{Design Goals and Constraints}

The system is architected around four primary goals. First, it preserves data privacy by executing text recognition, language understanding, and prompt synthesis entirely on-device; no source text leaves the macOS host. Second, it pursues reliability and fidelity by combining advanced preprocessing with custom-trained OCR models tuned to the target domains \cite{esser2020improving}. Third, it provides responsive interactive use through asynchronous orchestration and streaming interfaces. Fourth, it is reproducible and extensible: all transformations are deterministic when desired (fixed seeds, versioned models), and subsystems can be swapped without cascading changes.

\section{End-to-End Pipeline}

Figure~\ref{fig:pipeline-overview} summarizes the processing flow. Users acquire an image (screenshot or import). The Image Preprocessing and OCR subsystem performs adaptive enhancement and recognition with custom Tesseract models. The resulting text, together with document context, is transformed locally into a semantically rich, generation-ready prompt using a locally deployed GPT-OSS-20B model served by the Ollama runtime on macOS \cite{openai2025gptoss}. The prompt is then consumed by a FLUX-based image generation backend that returns one or more candidate images \cite{blackforestlabs2024flux, rombach2025flux}. Results and intermediate artifacts are persisted for auditability and downstream evaluation (Chapter~7).

\begin{figure}[t]
  \centering
  % Placeholder block diagram; replace with final vector graphic during camera-ready
  \fbox{\begin{minipage}[c][5.2cm][c]{0.92\linewidth}
  \vspace{0.8em}\centering
  \textbf{Pipeline Overview}\\[0.6em]
  Image Acquisition \(\rightarrow\) Preprocessing \& OCR (custom Tesseract) \(\rightarrow\)
  Local NLP (GPT-OSS-20B via Ollama) \(\rightarrow\) Prompted Image Generation (FLUX) \\
  Orchestration, Caching, Error Handling, and UI span the pipeline.
  \vspace{0.8em}
  \end{minipage}}
  \caption{High-level processing pipeline showing the flow from input image to synthesized image outputs with local privacy-preserving language processing and cloud-capable image generation.}
  \label{fig:pipeline-overview}
\end{figure}

\section{Image Preprocessing and OCR}

Robust text extraction is the foundation of the pipeline. The OCR subsystem builds on Tesseract's modern LSTM-based recognizer \cite{smith2007overview, hochreiter1997long} and is strengthened with custom training for the target domains. Training uses curated corpora with realistic degradations and typography variations, balancing printed and handwritten styles, and leverages sequence learning techniques that align naturally with unsegmented text lines \cite{graves2006connectionist}. We adopt a co-design philosophy whereby preprocessing and recognition are optimized jointly: adaptive contrast enhancement, denoising, local thresholding, and perspective correction are selected to maximize character- and word-level accuracy for the trained models \cite{esser2020improving}.

Preprocessing is parameterized to accommodate heterogeneous inputs encountered in screenshots and document captures. Table~\ref{tab:preproc} outlines typical operators and ranges used during both training-time augmentation and inference-time enhancement. The goal is not merely to denoise, but to shape the input distribution to match the statistics seen by the custom recognizers.

\begin{table}[t]
  \centering
  \caption{Preprocessing operators and representative parameterization used in training augmentation and inference-time enhancement. Ranges are design targets; measured effects are analyzed in Chapter~7.}
  \label{tab:preproc}
  \begin{tabular}{l l l}
    \hline
    Operator & Purpose & Representative setting \\
    \hline
    Adaptive contrast (CLAHE) & Improve local text/background separation & clip-limit 2.0--4.0 \\
    Bilateral/median filtering & Suppress noise while preserving edges & kernel 3--7 px \\
    Adaptive thresholding & Robust binarization under uneven lighting & window 11--31, C in [2,10] \\
    Morphological open/close & Fill gaps, remove speckles & kernel 2--5 px \\
  Deskew and rectification & Correct perspective and rotation & Hough-based, max tilt $\pm 5^{\circ}$ \\
    Line normalization & Stabilize height and baseline drift & target x-height 24--40 px \\
    \hline
  \end{tabular}
\end{table}

The OCR engine outputs text along with structural annotations (bounding boxes, line order), enabling downstream validation. Post-OCR correction applies lightweight language priors and domain lexica before handing text to the language module; corrections are logged for ablation in Chapter~7.

\section{Local Language Processing on macOS}

To preserve privacy and reduce round-trip latency, natural language understanding and prompt synthesis are executed locally using the GPT-OSS-20B open-source model deployed via Ollama on macOS \cite{openai2025gptoss}. The module performs three tasks: (i) error-tolerant normalization of noisy OCR text; (ii) semantic enrichment by inferring missing descriptors and resolving ambiguities with conservative heuristics; and (iii) prompt construction tailored to the requirements of the downstream generator (style hints, composition cues, safety constraints). The design follows contemporary practices in multimodal LLM systems \cite{qin2024comprehensive, jin2024mm}, but emphasizes deterministic behavior when required by fixing seeds and freezing templates for controlled experiments.

Prompt templates are versioned artifacts. Each template encodes content structure (subject, attributes, scene, lighting), stylistic controls, and negative constraints (undesired artifacts). The module provides a strict schema to the orchestrator to prevent accidental drift of prompt distributions during evaluation.

\section{Image Generation with FLUX}

The image generation backend integrates FLUX \cite{blackforestlabs2024flux} with architectural innovations in flow matching and parallel attention that enable high-fidelity, instruction-following synthesis \cite{rombach2025flux}. The subsystem exposes a job API that accepts normalized prompts, sampling configuration (steps, guidance, negative prompts), and optional seeds. Generated candidates are ranked with a lightweight heuristic incorporating prompt consistency and aesthetic proxies, facilitating downstream user selection. While this work focuses on faithful prompt adherence and controllability rather than unconstrained creativity, we acknowledge broader findings on the creative capacity of text-to-image models \cite{oppenlaender2022creativity}.

For interactive use, job processing is asynchronous and cancellable. Partial results can be surfaced progressively when supported by the backend, maintaining UI responsiveness even under heavy loads.

\section{Orchestration, Error Handling, and UI}

The coordination layer implements a non-blocking pipeline with explicit state transitions and bounded queues between subsystems. Status updates and errors propagate through a unified channel, allowing the UI to present actionable progress and recovery paths. On macOS, the native interface provides controls for OCR model selection, preprocessing intensity, language module presets, and generation styles. Internally, the implementation aligns with a modular separation of concerns: OCR model management, image preprocessing, language prompting, image generation service, screenshot capture/overlay, and view control. Table~\ref{tab:modules} summarizes the principal modules and their responsibilities as realized in the application codebase.

\begin{table}[t]
  \centering
  \caption{Primary modules and responsibilities in the macOS implementation. The mapping reflects the code organization used for experimentation and evaluation.}
  \label{tab:modules}
  \begin{tabular}{l l}
    \hline
    Module (Objective-C) & Responsibility \\
    \hline
    \texttt{SLScreenshot}/\texttt{SLScreenshotOverlay} & Screen capture, region selection, overlay interactions \\
    \texttt{SLImageProcessor} & Preprocessing pipeline configuration and execution \\
    \texttt{SLOCRModelManager}/\texttt{SLTesseract} & Model loading, OCR invocation, and result structuring \\
    \texttt{SLImageGenerationService} & FLUX backend integration, job lifecycle, and retries \\
    \texttt{SLImageStyleManager} & Prompt styling presets and negative constraints \\
    \texttt{SLViewController} & Orchestration, UI binding, and error presentation \\
    \hline
  \end{tabular}
\end{table}

Reliability is addressed through idempotent operations, bounded retries with exponential back-off for networked components, and structured error taxonomies (recoverable vs. terminal). All model and parameter versions are recorded alongside outputs to support reproducibility.

\section{Performance and Resource Budget}

Given the heterogeneous nature of inputs, we define target budgets rather than single-point metrics; empirical results are reported in Chapter~7. For typical single-region screenshots, the pipeline targets sub-second preprocessing and OCR on-device, prompt synthesis within interactive bounds on GPT-OSS-20B with Ollama, and image generation latency dependent on sampling configuration. Caching at image, text, and prompt levels avoids redundant computation during iterative refinement.

\section{Security, Privacy, and Reproducibility}

All text-bearing operations (preprocessing, OCR, normalization, and prompt construction) execute locally on macOS with no transmission of source text to external services. When remote backends are used for image generation, only distilled prompts (free of sensitive text content when required) are transmitted, and requests can be anonymized. Deterministic runs are supported via fixed seeds and locked configurations; logs contain model hashes and parameter digests to enable exact regeneration of results.

\section{Summary}

The presented architecture composes domain-optimized OCR with local language model and modern image synthesis into a cohesive, privacy-preserving system. Through modular boundaries, asynchronous orchestration, and careful co-design of preprocessing and recognition, the pipeline supports both controlled evaluation and practical interactive use. Subsequent chapters detail component-level implementations (Chapters~4--6) and provide comprehensive quantitative and qualitative assessment (Chapter~7).
