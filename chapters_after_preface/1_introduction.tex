\chapter{Introduction}

The integration of Optical Character Recognition (OCR), natural language processing, and generative AI enables the development of systems that transform textual content into visual representations. This capability addresses practical needs in document processing, accessibility technologies, and content generation applications.

This thesis presents a system that integrates custom-trained Tesseract OCR models, image preprocessing techniques, and AI-driven image generation for text-to-image transformation. The system bridges the gap between extracted textual content and visual outputs while maintaining accuracy and processing efficiency.

\section{Problem Statement and Motivation}

Recent AI developments in OCR, natural language understanding, and image synthesis create opportunities for system integration. However, combining these technologies into systems that transform extracted text into visual outputs presents technical challenges. Traditional approaches have limitations that affect real-world effectiveness.

Contemporary OCR systems achieve acceptable accuracy on clean text but encounter difficulties with handwritten content, low-quality images, or complex layouts. This accuracy degradation affects downstream processing. Research shows that OCR engines can benefit from specialized preprocessing techniques \cite{esser2020improving}.

Raw OCR output often lacks semantic richness for visual content transformation. The extracted text may contain errors, formatting inconsistencies, and insufficient descriptive elements for image generation, requiring natural language processing enhancement.

Large language models have advanced text processing capabilities. GPT-OSS-20B \cite{openai2025gptoss}, with 21 billion parameters and mixture-of-experts architecture, enables local deployment of language processing. The model's efficiency on consumer hardware with 16GB memory requirements supports privacy-preserving applications.

Text-to-image generation has advanced with models such as FLUX 1.1 Pro Ultra \cite{blackforestlabs2024flux}. These diffusion-based models generate images from textual descriptions using architectural innovations including flow matching and parallel attention mechanisms \cite{rombach2025flux}.

Multimodal AI systems that integrate information across different modalities are documented in recent surveys \cite{qin2024comprehensive, jin2024mm}. The practical implementation of systems combining OCR, language processing, and image generation remains an active research area.

\section{Research Objectives}

This research develops and evaluates a system that integrates custom-trained OCR technology, image preprocessing, natural language processing, and AI-driven image generation for text-to-image transformation. The objectives address technical challenges in multimodal AI system development.

First, this work enhances text extraction accuracy through custom Tesseract OCR models. This includes creating specialized training datasets, implementing preprocessing algorithms, and optimizing model parameters for different content types and image quality conditions.

Second, the research develops image preprocessing techniques to improve OCR accuracy. This includes adaptive filtering, contrast enhancement, brightness adjustment, and geometric correction optimized for custom-trained OCR models to handle lighting conditions, distortions, and artifacts.

Third, the work transforms raw OCR output into prompts for image generation through local deployment of GPT-OSS-20B using the Ollama framework, prompt engineering strategies, and error correction mechanisms.

Fourth, the research establishes a scalable system architecture that integrates multiple AI components while maintaining performance and user experience. This includes asynchronous processing, error handling, and system communication optimization.

Finally, the work evaluates the integrated system across performance dimensions including text extraction accuracy, prompt generation effectiveness, image synthesis quality, and user satisfaction.

\section{Scope and Contributions}

This thesis contributes to multimodal AI systems through an integrated architecture combining custom-trained OCR models, image preprocessing, locally deployed language models, and cloud-based image generation for text-to-image transformation.

The work develops custom Tesseract OCR models using domain-specific datasets and preprocessing techniques, achieving improved accuracy across different content types. The preprocessing pipeline incorporates adaptive algorithms for contrast enhancement, noise reduction, and geometric correction.

The deployment of GPT-OSS-20B locally demonstrates privacy-preserving AI applications on consumer hardware. The system architecture manages computational challenges by combining local AI inference with cloud services through asynchronous processing, error handling, and resource management.

The evaluation methodology assesses individual component performance and system-level integration effectiveness, providing insights for multimodal AI system development.

\section{System Architecture Overview}

The system employs a hybrid architecture combining local AI processing for privacy-sensitive operations with cloud services for image generation. The system consists of five components:

The Image Processing and OCR Module incorporates custom-trained Tesseract models with preprocessing capabilities for text extraction and quality validation.

The Natural Language Processing Module implements locally deployed GPT-OSS-20B using Ollama, transforming OCR output into prompts suitable for image generation while maintaining data privacy.

The Image Generation Service Module integrates with FLUX 1.1 Pro Ultra services through asynchronous processing for prompt submission and result retrieval.

The User Interface Module provides controls for OCR model selection, preprocessing parameters, and style customization through a native macOS interface.

The System Coordination Module manages workflow orchestration, resource allocation, and error handling across components.

\section{Thesis Organization}

This thesis is organized into eight chapters. Chapter 2 provides background on OCR technology, Tesseract architecture, GPT-OSS-20B, and diffusion-based image generation. Chapter 3 presents system architecture and design. 

Chapters 4-6 detail core system components: Chapter 4 covers OCR and preprocessing, Chapter 5 discusses natural language processing with GPT-OSS-20B deployment, and Chapter 6 presents image generation integration with FLUX 1.1 Pro Ultra.

Chapter 8 concludes with findings, limitations, and future work directions.



