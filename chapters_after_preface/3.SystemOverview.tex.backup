\chapter{System Overview}

This chapter presents the end-to-end system that transforms text contained in images into high-quality visual outputs by integrating custom-trained Tesseract OCR, image preprocessing, locally deployed large language model, and state-of-the-art text-to-image generation. The architecture is driven by practical constraints of privacy, latency, and robustness on commodity macOS hardware, while ensuring modularity for experimentation and rigorous evaluation. The design choices are grounded in prior advances in OCR and sequence model \cite{smith2007overview, graves2006connectionist, hochreiter1997long}, multimodal and LLM research \cite{qin2024comprehensive, jin2024mm}, as well as recent progress in open-source LLM deployment \cite{openai2025gptoss} and diffusion-based image synthesis \cite{blackforestlabs2024flux, rombach2025flux}.

\section{Design Goals and Constraints}

The system is architected around four primary goals. First, it preserves data privacy by executing text recognition, language understanding, and prompt synthesis entirely on-device; no source text leaves the macOS host. Second, it pursues reliability and fidelity by combining advanced preprocessing with custom-trained OCR models tuned to the target domains \cite{esser2020improving}. Third, it provides responsive interactive use through asynchronous orchestration and streaming interfaces. Fourth, it is reproducible and extensible: all transformations are deterministic when desired (fixed seeds, versioned models), and subsystems can be swapped without cascading changes.

\section{End-to-End Pipeline}

Figure~\ref{fig:pipeline-overview} summarizes the processing flow. Users acquire an image (screenshot or import). The Image Preprocessing and OCR subsystem performs adaptive enhancement and recognition with custom Tesseract models. The resulting text, together with document context, is transformed locally into a semantically rich, generation-ready prompt using a locally deployed GPT-OSS-20B model served by the Ollama runtime on macOS \cite{openai2025gptoss}. The prompt is then consumed by a FLUX-based image generation backend that returns one or more candidate images \cite{blackforestlabs2024flux, rombach2025flux}. Results and intermediate artifacts are persisted for auditability and downstream evaluation (Chapter~7).

\begin{figure}[t]
  \centering
  % Simple placeholder; replace with final graphic later
  \vspace{3cm}
  \caption{Pipeline overview.}
  \label{fig:pipeline-overview}
\end{figure}

\section{Image Preprocessing and OCR}

Robust text extraction is the foundation of the pipeline. The OCR subsystem builds on Tesseract's modern LSTM-based recognizer \cite{smith2007overview, hochreiter1997long} and is strengthened with custom training for the target domains. Training uses curated corpora with realistic degradations and typography variations, balancing printed and handwritten styles, and leverages sequence learning techniques that align naturally with unsegmented text lines \cite{graves2006connectionist}. We adopt a co-design philosophy whereby preprocessing and recognition are optimized jointly: adaptive contrast enhancement, denoising, local thresholding, and perspective correction are selected to maximize character- and word-level accuracy for the trained models \cite{esser2020improving}.

Preprocessing is parameterized to accommodate heterogeneous inputs encountered in screenshots and document captures. Table~\ref{tab:preproc} outlines typical operators and ranges used during both training-time augmentation and inference-time enhancement. The goal is not merely to denoise, but to shape the input distribution to match the statistics seen by the custom recognizers.

\begin{table}[t]
  \centering
  \caption{Preprocessing operators and representative parameterization used in training augmentation and inference-time enhancement. Ranges are design targets; measured effects are analyzed in Chapter~7.}
  \label{tab:preproc}
  \small
  \begin{tabular}{lll}
    \hline
  \begin{center}
  \emph{[Pipeline overview graphic placeholder]}
  \end{center}
    Line normalization & Stabilize height and baseline drift & target x-height 24--40 px \\
    \hline
  \end{tabular}
\end{table}

The OCR engine outputs text along with structural annotations (bounding boxes, line order), enabling downstream validation. Post-OCR correction applies lightweight language priors and domain lexica before handing text to the language module; corrections are logged for ablation in Chapter~7.

  \begin{itemize}
    \item Adaptive contrast (CLAHE): Improve local text/background separation; clip-limit 2.0--4.0.
    \item Bilateral/median filtering: Suppress noise while preserving edges; kernel 3--7 px.
    \item Adaptive thresholding: Robust binarization under uneven lighting; window 11--31, C in [2,10].
    \item Morphological open/close: Fill gaps, remove speckles; kernel 2--5 px.
    \item Deskew and rectification: Correct perspective and rotation; Hough-based, max tilt $\pm 5^{\circ}$.
    \item Line normalization: Stabilize height and baseline drift; target x-height 24--40 px.
  \end{itemize}
  \caption{Primary modules and responsibilities in the macOS implementation. The mapping reflects the code organization used for experimentation and evaluation.}
  \label{tab:modules}
  \small
  \begin{tabular}{ll}
    \hline
    Module (Objective-C) & Responsibility \\
    \hline
    SLScreenshot/\texttt{SLScreenshotOverlay} & Screen capture, region selection, overlay interactions \\
    SLImageProcessor & Preprocessing pipeline configuration and execution \\
    SLOCRModelManager/\texttt{SLTesseract} & Model loading, OCR invocation, and result structuring \\
    SLImageGenerationService & FLUX backend integration, job lifecycle, and retries \\
    SLImageStyleManager & Prompt styling presets and negative constraints \\
    SLViewController & Orchestration, UI binding, and error presentation \\
    \hline
  \end{tabular}
\end{table}

Reliability is addressed through idempotent operations, bounded retries with exponential back-off for networked components, and structured error taxonomies (recoverable vs. terminal). All model and parameter versions are recorded alongside outputs to support reproducibility.

  \begin{itemize}
    \item SLScreenshot/SLScreenshotOverlay: Screen capture, region selection, overlay interactions.
    \item SLImageProcessor: Preprocessing pipeline configuration and execution.
    \item SLOCRModelManager/SLTesseract: Model loading, OCR invocation, and result structuring.
    \item SLImageGenerationService: FLUX backend integration, job lifecycle, and retries.
    \item SLImageStyleManager: Prompt styling presets and negative constraints.
    \item SLViewController: Orchestration, UI binding, and error presentation.
  \end{itemize}
    \hline
