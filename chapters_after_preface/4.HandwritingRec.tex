\chapter{Optical  Character Recognition}


\section{Training the Tesseract Model}

\subsection{Introduction to Tesseract Model Training}

OCR systems are critical tools for document digitization and processing of textual content. In this domain, Tesseract OCR has emerged as a highly capable and freely accessible OCR engine, which is recognized for its wide-ranging adaptability in support of different languages and character sets. The latest version, Tesseract v5, is a major advancement due to its inclusion of a Long Short-Term Memory network structure, which is a major advancement compared to its predecessor versions, with substantially improved recognition accuracy \cite{smith2007overview}.

Although the standard pre-trained Tesseract models provide reasonable results for standard documents, certain applications often require custom-trained models tailored for specific document layouts, fonts, or degraded text conditions. This section outlines a comprehensive process for custom Tesseract model training under Windows, focusing majorly on identifying characters in English. The custom model training process presented here is based on a systematic process that can be modified and adapted for various recognition purposes,  presenting a flexible platform for practitioners and researchers for model development and optimization.

Our training implementation leverages datasets from \textit{Kaggle}, comprising images along with corresponding ground truth files (.box, .txt, and .gt.txt formats). The resources serve as a foundation for constructing a robust Tesseract recognition model capable of addressing domain-specific OCR-oriented challenges. The methodology written in this chapter elaborates the end-to-end process of training,  from environment set-up to model evaluation, offering deep-dives of the process of the Tesseract OCR model training.

\subsection{Theoretical Framework for Tesseract Training}

Based on LSTM technology, Tesseract uses a complex neural network architecture that marks a paradigm change from the conventional feature-based method applied in previous versions. LSTMs efficiently capture contextual information and control long-range dependencies in text, hence improving sequence recognition tasks\cite{hochreiter1997long}. For OCR uses, where character recognition gains much from contextual analysis, this functionality is especially beneficial.

Operating on a hierarchical neural network structure, the LSTM implementation in Tesseract v5 handles visual features at several degrees of abstraction. Comprising multiple important components—convolutional layers for feature extraction, LSTM layers for sequential processing, and fully linked layers for character classification—the network  architecture helps the model to learn intricate patterns in textual input while keeping resilience against changes in character appearance.

Tesseract models' training procedure is supervised learning, in which case-labeled examples guide network parameter optimization. This optimization aims to reduce, measured by an error function, the difference between expected and actual character sequences. Using a backpropagation via time mechanism, the training approach drives error gradients across LSTM network recurrent connections \cite{graves2006connectionist}.

Tesseract model training depends critically on the choice of suitable network parameters and training hyperparameters. The network specification, encapsulated in the \textit{--net\_spec} parameter, defines the architecture of the neural network, including layer types, dimensions, and connections. Proper configuration of this specification greatly affects model performance and should correspond with the complexity of the recognition task.

\subsection{Materials and Experimental Setup}
\subsubsection{Hardware and Software Requirements
}
The training of Tesseract LSTM models demands significant computational resources, particularly for complex character sets or large training data. For our implementation, we utilized a machine  with the specifications below:

\begin{itemize}
    \item \texttt{Intel Core i7-10700K} CPU (3.8 GHz, 8 cores)
    \item 32 GB DDR4 RAM
    \item \texttt{NVIDIA GeForce RTX 3080} GPU with 10 GB VRAM
    \item 1000 GB SSD storage
\end{itemize}

For software requirements, our implementation relied on the following components:

\begin{itemize}
    \item \texttt{Windows 10 Professional} (64-bit)
    \item \texttt{Tesseract-OCR v5.0.1.20220118}
    \item \texttt{tessdata\_best} (high accuracy model files)
    \item \texttt{langdata\_lstm} (language training data)
    \item \texttt{PowerShell 7.2} (for command execution)
    \item \texttt{Notepad++} (for text file editing)
    \item \texttt{Java Runtime Environment 11} (for auxiliary tools)
\end{itemize}
Additionally, for visualizing and validating box files, we utilized jTessBoxEditor as a supplementary tool, although this tool was not essential to the core training process.

\subsubsection{Dataset Preparation}
Our training implementation utilized datasets from \textit{Kaggle}, which offered a diverse collection of open-source English text images with corresponding ground truth annotations. The image-text pair dataset structure included the following components:

\begin{itemize}
    \item \texttt{TIFF} format images containing text samples
    \item \texttt{.box} files specifying character bounding boxes
    \item \texttt{.txt} files containing transcribed text
    \item \texttt{.gt.txt} files with ground truth information
\end{itemize}

The dataset included several font styles, sizes, and text complexity to ensure model robustness. Special focus was given to adding instances of difficult recognition situations such:


\begin{itemize}
    \item Variable text orientations
    \item Diverse font families (serif, sans-serif, monospace)
    \item Different font weights and styles
    \item Varying levels of image noise and degradation
    \item Multiple character spacing patterns
\end{itemize}

We used a preprocessing script to convert the raw data into the LSTM training format (.lstmf) in order to prepare the dataset for Tesseract training. The Powershell script execution followed this pattern:

\begin{verbatim}
Get-ChildItem -Filter *.tiff | ForEach-Object {
  $baseName = $_.BaseName
  tesseract $_.FullName $baseName --psm 6 lstmbox
  tesseract $_.FullName $baseName --psm 6 lstm.train
}

\end{verbatim}

This script generates corresponding .lstmf files necessary for LSTM training by processing all TIFF images in the directory. The Page Segmentation Mode (PSM) was set to 6, indicating the assumption of a single uniform block of text in each image.

\subsection{ Methodology for Tesseract Model Training}

\subsubsection{Preparation Phase
}
The first phase of model training consisted in setting the suitable directory structure and environment. We created a specific directory structure to arrange the training materials:

\vspace{0.8cm}

\dirtree{%
.1 E:\textbackslash TESSERACT\_TRAINING.
.2 langdata\_lstm.
.2 output.
.2 tessdata\_best.
.2 tmp.
}

\vspace{0.8cm}

While keeping clear boundaries between component groups, this framework centralized all training materials. High-accuracy pre-trained models located in the \texttt{tessdata\_best} directory were references for our own model construction. Language-specific data required for model initialization can be found in the \texttt{langdata\_lstm} directory. While the \texttt{tmp} directory contained temporary files generated during the training process, the \texttt{output} directory was designated for produced models and training checkpoints.

After directory setup, we installed Tesseract-OCR with English language capability. The installation path was added to the system environment variables to enable command-line execution without path specification.

\subsubsection{Character Set Analysis and Preparation}
A essential element of model training was specifying the character set targeted for recognition. Our English model focused on:


\begin{itemize}
    \item Uppercase and lowercase Latin alphabets (52 characters)
    \item Numeric digits (10 characters)
    \item Punctuation marks and special symbols (approximately 32 characters)
    \item Common ligatures and diacritical marks (as needed)
\end{itemize}

To analyze the existing character set in the tessdata\_best English model, we executed:

\begin{verbatim}
combine_tessdata -u 
E:\TESSERACT_TRAINING\tessdata_best\eng.traineddata 
E:\TESSERACT_TRAINING\tessdata_best\eng
\end{verbatim}

This command extracted components from the pre-trained model, including the character set information. We then converted the DAWG (Directed Acyclic Word Graph) dictionaries to text format for analysis and potential modification, here we use :

\begin{verbatim}
dawg2wordlist E:\TESSERACT_TRAINING\tessdata_best\eng.lstm-unicharset 
E:\TESSERACT_TRAINING\tessdata_best\eng.lstm-word-dawg 
E:\TESSERACT_TRAINING\tessdata_best\word.txt
\end{verbatim}

Similar operations were applied to numbers and  punctuation DAWG types.

\subsubsection{Character Set Generation}

Our custom model's character set was defined in a text file (eng\_custom.txt), without spaces, line breaks, or repetition among all the intended characters. This file served as the basis of generating the LSTM unicharset file needed for model training. We then developed the character set box file by executing: 


\begin{Verbatim}[breaklines=true]
text2image --text E:\TESSERACT_TRAINING\eng_custom.txt --outputbase E:\TESSERACT_TRAINING\eng_custom --fonts_dir C:\Windows\Fonts --font="Arial" --fontconfig_tmpdir E:\TESSERACT_TRAINING\tmp
\end{Verbatim}




% hahahaha

\begin{align}
    f_t &= \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) \\
    i_t &= \sigma(W_i \cdot [h_{t-1}, x_t] + b_i) \\
    \tilde{C}_t &= \tanh(W_C \cdot [h_{t-1}, x_t] + b_C) \\
    C_t &= f_t * C_{t-1} + i_t * \tilde{C}_t \\
    o_t &= \sigma(W_o \cdot [h_{t-1}, x_t] + b_o) \\
    h_t &= o_t * \tanh(C_t)
\end{align}

where:
\begin{itemize}
    \item $f_t$, $i_t$, and $o_t$ represent the forget, input, and output gates, respectively.
    \item $\tilde{C}_t$ denotes the candidate cell state.
    \item $C_t$ is the cell state.
    \item $h_t$ is the hidden state.
    \item $W$ and $b$ are the weight matrices and bias vectors.
    \item $\sigma$ is the sigmoid activation function.
    \item $\tanh$ is the hyperbolic tangent activation function.
\end{itemize}